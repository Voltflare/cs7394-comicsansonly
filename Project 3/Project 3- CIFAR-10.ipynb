{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fa96113",
   "metadata": {},
   "source": [
    " ## **Clean the Data (deal with missing values):**\n",
    "\n",
    "There are no missing values in this dataset, and each image has the exact same shape. From the website: \"The CIFAR-10 dataset consists of *60000 32x32 colour images in 10 classes, with 6000 images per class.* There are **50000 training images and 10000 test images.**\n",
    "\n",
    "*The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class.* The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\"\n",
    "\n",
    "For this reason, train/test splitting is already done intrinsically (by the owner of the CIFAR-10 dataset), and the data must simply be loaded and differentiated properly to be properly used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b61857e",
   "metadata": {},
   "source": [
    "## **Create/Implement a Custom Transformer:**\n",
    "\n",
    "Each image starts as a 32x32x3 vector of data, containing the RGB values for each pixel in a 32x32 image one after another. To be used in most machine learning algorithms, each image must be one single instance (row). Thus, each image will be reshaped to one vector of (32 * 32 * 3) = 3072 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c7e6c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3072)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3072)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (10000, 3072)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "#eloquent solution on stack overflow:\n",
    "#https://stackoverflow.com/questions/37512290/reading-cifar10-dataset-in-batches\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from six.moves import cPickle as pickle\n",
    "import os\n",
    "import platform\n",
    "from subprocess import check_output\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "img_rows, img_cols = 32, 32\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "def load_pickle(f):\n",
    "    version = platform.python_version_tuple()\n",
    "    if version[0] == '2':\n",
    "        return  pickle.load(f)\n",
    "    elif version[0] == '3':\n",
    "        return  pickle.load(f, encoding='latin1')\n",
    "    raise ValueError(\"invalid python version: {}\".format(version))\n",
    "\n",
    "def load_CIFAR_batch(filename):\n",
    "    \"\"\" load single batch of cifar \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        datadict = load_pickle(f)\n",
    "        X = datadict['data']\n",
    "        Y = datadict['labels']\n",
    "        X = X.reshape(10000,3072)\n",
    "        Y = np.array(Y)\n",
    "        return X, Y\n",
    "\n",
    "def load_CIFAR10(ROOT):\n",
    "    \"\"\" load all of cifar \"\"\"\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for b in range(1,6): #there are five files (data_batch_1 through data_batch_5)\n",
    "        f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
    "        X, Y = load_CIFAR_batch(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)\n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    del X, Y\n",
    "    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
    "    return Xtr, Ytr, Xte, Yte\n",
    "\n",
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=10000):\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cifar-10-python.tar\\cifar-10-python\\cifar-10-batches-py'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    x_train = X_train.astype('float32')\n",
    "    x_test = X_test.astype('float32')\n",
    "\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "\n",
    "    return x_train, y_train, X_val, y_val, x_test, y_test\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = get_CIFAR10_data()\n",
    "\n",
    "\n",
    "print('Train data shape: ', x_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', x_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', x_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d651288",
   "metadata": {},
   "source": [
    "## Use OvO or OvR classifier:\n",
    "\n",
    "One of the most common approaches to machine learning multiclass problems is training several binary classifiers against each other and taking the best result. The two methods that utilize this are OvO (one versus one) and OvR (one versus rest). When using binary methods (like Support Vector Machines) against multiclass data/problems, certain packages will intrinsically create an OvO/OvR model to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25253dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svm.fit(x_train, y_train)\n",
    "\n",
    "svm.predict(x_train[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeb4556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To prove that it is using OvO/OvR under the hood:\n",
    "some_animal_scores = svm.decision_function(x_train[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb7d522",
   "metadata": {},
   "source": [
    " ## **Use sklearn.neighbors.KNeighborsClassifier:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a82b5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e7ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As an initial test, let's use the default for K in sci-kit learn's KNN algorithm (k = 5)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6e9766",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fcf042",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing on a single sample\n",
    "knn.predict(x_train[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8044dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.predict_proba(x_train[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0d9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class labels =  airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
    "#So, the classifier thinks this is a deer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38047b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's see what the image actually is, visually\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = x_train[0, :]\n",
    "image = np.reshape(image, (32,32,3), order='F' ) \n",
    "plt.imshow(image)\n",
    "\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b379f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this appears to be a frog (class 6), not a deer (class 4)\n",
    "#Was this just a fluke, though, or are none of the predictions particularly accurate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cf83c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "mae_A = cross_val_score(knn, x_val, y_val, scoring=\"neg_mean_absolute_error\", cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334dea51",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mae_A.mean()\n",
    "stdAccuracy = mae_A.std()\n",
    "print(\"Mean Absolute Error: %.2f, Standard Deviation : %.2f\" % (mae, stdAccuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a7deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = cross_val_score(knn, x_val, y_val, scoring=\"accuracy\", cv=10)\n",
    "print(\"Accuracy: %.2f, Standard Deviation: %.2f\" % (accuracy.mean(), accuracy.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c95a3b6",
   "metadata": {},
   "source": [
    "At least it's *consistently* wrong, right? Let's try to make it better with GridSearch.\n",
    "\n",
    "## **Use Grid Search CV or RandomizedSearch CV to tune hyperparameters for a model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d1231fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 30 candidates, totalling 300 fits\n"
     ]
    }
   ],
   "source": [
    "#training with grid-search from https://machinelearningknowledge.ai/knn-classifier-in-sklearn-using-gridsearchcv-with-example/\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "ks = list(range(1, 31)) #past 20-30 is too much energy for this jupyter instance\n",
    "param_grid = dict(n_neighbors=ks)\n",
    "\n",
    "grid = GridSearchCV(knn, param_grid, cv=10, scoring='accuracy', return_train_score=False,verbose=1)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid_search=grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4336eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy is  34.33673469387755  with a k value of  {'n_neighbors': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Accuracy is \", grid_search.best_score_*100, \" with a k value of \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9215f345",
   "metadata": {},
   "source": [
    "Based on our gridsearch, our best value for K is 1.\n",
    "\n",
    "Now, with this model, we can test and deploy it.\n",
    "\n",
    "## **Evaluate your system on the Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d1413ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_updated = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dfef77d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_updated.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d1db65c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: -2.41, Standard Deviation : 0.06\n"
     ]
    }
   ],
   "source": [
    "mae_B = cross_val_score(knn_updated, x_test, y_test, scoring=\"neg_mean_absolute_error\", cv=10)\n",
    "mae_updated = mae_B.mean()\n",
    "stdAccuracy_updated = mae_B.std()\n",
    "print(\"Mean Absolute Error: %.2f, Standard Deviation : %.2f\" % (mae_updated, stdAccuracy_updated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec6ca8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.29, Standard Deviation: 0.01\n"
     ]
    }
   ],
   "source": [
    "accuracy_updated = cross_val_score(knn_updated, x_test, y_test, scoring=\"accuracy\", cv=10)\n",
    "print(\"Accuracy: %.2f, Standard Deviation: %.2f\" % (accuracy_updated.mean(), accuracy_updated.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b824d8ff",
   "metadata": {},
   "source": [
    "Optimizing our parameters with GridSearch lowered our MAE from 2.76 to 2.41 and raised our accuracy from 22% to 29%, an increase of over 30% in accuracy and a 15% decrease in MAE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
